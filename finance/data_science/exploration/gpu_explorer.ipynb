{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "from finance.utilities import utils\n",
    "from finance.data_science.utilities import financial_utils, time_series_utils, cluster_utils, random_forest_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_matplotlib_converters()\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>average_open_hundred_days</th>\n",
       "      <th>average_open_fifty_days</th>\n",
       "      <th>average_open_ten_days</th>\n",
       "      <th>high_open_hundred_days</th>\n",
       "      <th>low_open_hundred_days</th>\n",
       "      <th>average_volume_hundred_days</th>\n",
       "      <th>average_volume_ten_days</th>\n",
       "      <th>average_daily_finish_ten_days</th>\n",
       "      <th>average_daily_range_ten_days</th>\n",
       "      <th>open_ten_days_forward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-18 06:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>62546377.0</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>62546377.0</td>\n",
       "      <td>62546377.0</td>\n",
       "      <td>1.072961</td>\n",
       "      <td>7.153077</td>\n",
       "      <td>32.144134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-19 06:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>30.713519</td>\n",
       "      <td>15234143.0</td>\n",
       "      <td>31.630007</td>\n",
       "      <td>31.630007</td>\n",
       "      <td>31.630007</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>30.713519</td>\n",
       "      <td>38890260.0</td>\n",
       "      <td>38890260.0</td>\n",
       "      <td>1.452968</td>\n",
       "      <td>4.716560</td>\n",
       "      <td>32.367668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-22 06:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>29.551144</td>\n",
       "      <td>6577866.0</td>\n",
       "      <td>30.937053</td>\n",
       "      <td>30.937053</td>\n",
       "      <td>30.937053</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>29.551144</td>\n",
       "      <td>28119462.0</td>\n",
       "      <td>28119462.0</td>\n",
       "      <td>0.327849</td>\n",
       "      <td>4.083215</td>\n",
       "      <td>32.725322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-23 06:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>30.400572</td>\n",
       "      <td>5975608.0</td>\n",
       "      <td>30.802933</td>\n",
       "      <td>30.802933</td>\n",
       "      <td>30.802933</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>29.551144</td>\n",
       "      <td>22583498.5</td>\n",
       "      <td>22583498.5</td>\n",
       "      <td>0.692954</td>\n",
       "      <td>3.710659</td>\n",
       "      <td>32.367668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-24 06:00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>28.701717</td>\n",
       "      <td>4843228.0</td>\n",
       "      <td>30.382689</td>\n",
       "      <td>30.382689</td>\n",
       "      <td>30.382689</td>\n",
       "      <td>32.546495</td>\n",
       "      <td>28.701717</td>\n",
       "      <td>19035444.4</td>\n",
       "      <td>19035444.4</td>\n",
       "      <td>0.420243</td>\n",
       "      <td>3.245709</td>\n",
       "      <td>32.367668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      market_datetime symbol       open      volume  \\\n",
       "0 1999-11-18 06:00:00      A  32.546495  62546377.0   \n",
       "1 1999-11-19 06:00:00      A  30.713519  15234143.0   \n",
       "2 1999-11-22 06:00:00      A  29.551144   6577866.0   \n",
       "3 1999-11-23 06:00:00      A  30.400572   5975608.0   \n",
       "4 1999-11-24 06:00:00      A  28.701717   4843228.0   \n",
       "\n",
       "   average_open_hundred_days  average_open_fifty_days  average_open_ten_days  \\\n",
       "0                  32.546495                32.546495              32.546495   \n",
       "1                  31.630007                31.630007              31.630007   \n",
       "2                  30.937053                30.937053              30.937053   \n",
       "3                  30.802933                30.802933              30.802933   \n",
       "4                  30.382689                30.382689              30.382689   \n",
       "\n",
       "   high_open_hundred_days  low_open_hundred_days  average_volume_hundred_days  \\\n",
       "0               32.546495              32.546495                   62546377.0   \n",
       "1               32.546495              30.713519                   38890260.0   \n",
       "2               32.546495              29.551144                   28119462.0   \n",
       "3               32.546495              29.551144                   22583498.5   \n",
       "4               32.546495              28.701717                   19035444.4   \n",
       "\n",
       "   average_volume_ten_days  average_daily_finish_ten_days  \\\n",
       "0               62546377.0                       1.072961   \n",
       "1               38890260.0                       1.452968   \n",
       "2               28119462.0                       0.327849   \n",
       "3               22583498.5                       0.692954   \n",
       "4               19035444.4                       0.420243   \n",
       "\n",
       "   average_daily_range_ten_days  open_ten_days_forward  \n",
       "0                      7.153077              32.144134  \n",
       "1                      4.716560              32.367668  \n",
       "2                      4.083215              32.725322  \n",
       "3                      3.710659              32.367668  \n",
       "4                      3.245709              32.367668  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    with raw as (\n",
    "        select \n",
    "            market_datetime\n",
    "            , symbol\n",
    "            , open\n",
    "            , volume\n",
    "            , avg(open) over (partition by symbol order by market_datetime rows between 100 preceding and current row) as average_open_hundred_days\n",
    "            , avg(open) over (partition by symbol order by market_datetime rows between 50 preceding and current row) as average_open_fifty_days\n",
    "            , avg(open) over (partition by symbol order by market_datetime rows between 10 preceding and current row) as average_open_ten_days\n",
    "            , max(open) over (partition by symbol order by market_datetime rows between 100 preceding and current row) as high_open_hundred_days\n",
    "            , min(open) over (partition by symbol order by market_datetime rows between 100 preceding and current row) as low_open_hundred_days\n",
    "            , avg(volume) over (partition by symbol order by market_datetime rows between 100 preceding and current row) as average_volume_hundred_days\n",
    "            , avg(volume) over (partition by symbol order by market_datetime rows between 10 preceding and current row) as average_volume_ten_days\n",
    "            , avg(open - close) over (partition by symbol order by market_datetime rows between 10 preceding and current row) as average_daily_finish_ten_days\n",
    "            , avg(high - low) over (partition by symbol order by market_datetime rows between 10 preceding and current row) as average_daily_range_ten_days\n",
    "            , lead(open, 10) over (partition by symbol order by market_datetime) as open_ten_days_forward\n",
    "        from td.equities)\n",
    "    select * \n",
    "    from raw\n",
    "    where open_ten_days_forward is not null\n",
    "    limit 10000\n",
    "    \"\"\"\n",
    "\n",
    "df = utils.query_db(query=query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cluster_utils.encode_one_hot(df=df, column='symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "    df = cluster_utils.normalize(df=df, column=col, subset='symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.copy()\n",
    "train = train.drop(columns=['symbol'])\n",
    "train['market_datetime'] = train['market_datetime'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train['open_ten_days_forward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 80000\n",
    "train_x = train.iloc[1:split_size].values\n",
    "train_y = train_target.iloc[1:split_size].values\n",
    "\n",
    "test_x = train.iloc[split_size+1:-1].values\n",
    "test_y = train_target.iloc[split_size+1:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035200\n",
      "2359296\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "print(torch.cuda.memory_cached())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.tensor(train_x).cuda(0)\n",
    "tensor_y = torch.tensor(train_y).cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 15\n",
    "output_size = 1\n",
    "learning_rate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "model = torch.nn.Linear(input_size, output_size).cuda(0)\n",
    "\n",
    "criterion = torch.nn.MSELoss().cuda(0)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(1):\n",
    "    for t in range(2):\n",
    "        prediction = model(tensor_x.float()).cuda(0)\n",
    "\n",
    "        loss = criterion(prediction, tensor_y.float()).cuda(0)\n",
    "\n",
    "        optimizer.zero_grad() # .cuda(0)\n",
    "        loss.backward() #.cuda(0)\n",
    "        optimizer.step() #.cuda(0)\n",
    "        \n",
    "        loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1446]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster as skcluster\n",
    "import torch\n",
    "from torch import nn, functional, optim, autograd\n",
    "\n",
    "from finance.utilities import utils, cluster_utils\n",
    "\n",
    "\n",
    "class TorchNN:\n",
    "    def __init__(self, \n",
    "                 train_x=pd.DataFrame, \n",
    "                 train_y=pd.DataFrame,\n",
    "                 test_x=pd.DataFrame, \n",
    "                 test_y=pd.DataFrame, \n",
    "                 learning_rate=0,\n",
    "                 momentum=.9, \n",
    "                 hidden_size=None, \n",
    "                 out_features=1):\n",
    "        self.train_x = torch.tensor(train_x.values).float().view(1, -1)\n",
    "        self.train_y = torch.tensor(train_y.values).float()\n",
    "        # self.test_x = torch.tensor(test_x)\n",
    "        # self.test_y = torch.tensor(test_y)\n",
    "        self.size = train_x.shape[0] * train_x.shape[1]\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.linear_one = nn.Linear(in_features=self.size, out_features=hidden_size[0]).float()\n",
    "        self.linear_two = nn.Linear(in_features=hidden_size[0], out_features=out_features).float()\n",
    "\n",
    "    def forward(self):\n",
    "        # output = self.linear_one(self.train_x.view(-1, 1))\n",
    "        output = self.linear_one(self.train_x.view(self.train_x.size(0), -1))\n",
    "        # output = self.linear_one(self.train_x)\n",
    "        output = functional.F.relu(output)\n",
    "        output = self.linear_two(output)\n",
    "        return output\n",
    "\n",
    "    def optimizer(self, model):\n",
    "        optimizer = optim.SGD(nn.Module.parameters(model), lr=self.learning_rate, momentum=self.momentum)\n",
    "        return optimizer\n",
    "\n",
    "    def loss_criterion(self):\n",
    "        return nn.NLLLoss()\n",
    "\n",
    "    def train_network(self, model):\n",
    "        for idx, row in self.train_x.iterrows():\n",
    "            data = autograd.Variable(row)\n",
    "            target = autograd.Variable(self.train_y[idx])\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            net_out = model(data)\n",
    "            loss = self.loss_criterion(net_out, target)\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    query = \"\"\"\n",
    "        select\n",
    "            e.symbol\n",
    "            , e.market_datetime\n",
    "            , e.open\n",
    "            , e.high\n",
    "            , e.low\n",
    "            , e.close\n",
    "            , e.volume\n",
    "        from td.equities as e\n",
    "        where \n",
    "        --left(e.symbol, 1) = 'A'\n",
    "        e.symbol = 'AA'\n",
    "        order by e.market_datetime\n",
    "        limit 100\n",
    "        \"\"\"\n",
    "    df = utils.query_db(query=query)\n",
    "    for col in ['open']:\n",
    "        df = cluster_utils.normalize(df=df, column=col, subset='symbol')\n",
    "    df['market_datetime'] = df['market_datetime'].astype(int)\n",
    "\n",
    "    train = df.copy()\n",
    "    train = train.drop(columns=['symbol'])\n",
    "    train['market_datetime'] = train['market_datetime'].astype(int)\n",
    "\n",
    "    train_target = train['open'].shift(-1)\n",
    "\n",
    "    split_size = 80000\n",
    "    train_x = train.iloc[1:split_size]\n",
    "    train_y = train_target.iloc[1:split_size]\n",
    "\n",
    "    test_x = train.iloc[split_size + 1:-1]\n",
    "    test_y = train_target.iloc[split_size + 1:-1]\n",
    "\n",
    "    model = TorchNN(train_x=train_x, train_y=train_y, hidden_size=(1,)).forward()\n",
    "    print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 3.5007288455963135\n",
      "199 0.13228681683540344\n",
      "299 0.008658592589199543\n",
      "399 0.0007689027697779238\n",
      "499 7.713446393609047e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
